{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBtjN4E9XKp1"
      },
      "source": [
        "# Fine-Tuning Pretrained SlowFast Model on HEROES Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK4CfrBKXKp2"
      },
      "outputs": [],
      "source": [
        "# Google Drive 마운트 및 데이터셋 압축 해제\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Google Drive 마운트\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 압축 파일 경로와 해제할 디렉토리 경로 지정\n",
        "zip_file_path = '/content/drive/MyDrive/HEROES.zip'\n",
        "extract_dir = '/content/drive/MyDrive/URP/dataset'\n",
        "\n",
        "# 압축 파일 해제\n",
        "'''\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "!apt install -y ffmpeg"
      ],
      "metadata": {
        "id": "MT5s4y-obmhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install av"
      ],
      "metadata": {
        "id": "YgrYNBj0bpyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorchvideo"
      ],
      "metadata": {
        "id": "3QHNzKC_Zk9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2SdAM_8XKp3"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 분리 및 로드\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "import torchvision.io as io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorchvideo.models as models\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 데이터셋 디렉토리 설정\n",
        "data_dir = '/content/drive/MyDrive/URP/dataset/HEROES'\n",
        "emotions = ['BOREDOM', 'DISGUST', 'HAPPINESS', 'INTEREST']\n",
        "\n",
        "# 데이터셋 파일 경로와 라벨 수집\n",
        "samples = []\n",
        "for emotion in emotions:\n",
        "    emotion_dir = os.path.join(data_dir, emotion)\n",
        "    for id_folder in os.listdir(emotion_dir):\n",
        "        id_dir = os.path.join(emotion_dir, id_folder)\n",
        "        for file_name in os.listdir(id_dir):\n",
        "            file_path = os.path.join(id_dir, file_name)\n",
        "            samples.append((file_path, emotions.index(emotion)))\n",
        "\n",
        "# Train, Test 데이터셋 분리 (80% Train, 20% Test)\n",
        "train_samples, test_samples = train_test_split(samples, test_size=0.2, random_state=42)\n",
        "\n",
        "# Validation 데이터셋 분리 (Train 데이터의 12.5%를 Validation 데이터셋으로 사용)\n",
        "train_samples, val_samples = train_test_split(train_samples, test_size=0.125, random_state=42)\n",
        "\n",
        "print(f\"Train samples: {len(train_samples)}\")\n",
        "print(f\"Validation samples: {len(val_samples)}\")\n",
        "print(f\"Test samples: {len(test_samples)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlTRY9gaXKp3"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 클래스 정의\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, samples, transform=None):\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "        video, _, _ = io.read_video(file_path, pts_unit='sec')\n",
        "        if self.transform:\n",
        "            video = self.transform(video)\n",
        "        return video, label\n",
        "\n",
        "# 데이터셋 변환 설정\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# 데이터셋 로드\n",
        "train_dataset = EmotionDataset(train_samples, transform=transform)\n",
        "val_dataset = EmotionDataset(val_samples, transform=transform)\n",
        "test_dataset = EmotionDataset(test_samples, transform=transform)\n",
        "\n",
        "# DataLoader 설정\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDqHUCDMXKp3"
      },
      "outputs": [],
      "source": [
        "# Kinetics400으로 사전학습된 SlowFast R50 모델 불러오기 및 수정\n",
        "model = models.create_slowfast(model_num_class=4)\n",
        "\n",
        "# 손실 함수 및 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyLXUEtNXKp4"
      },
      "outputs": [],
      "source": [
        "# GPU 사용 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 모델을 GPU로 이동\n",
        "model = model.to(device)\n",
        "\n",
        "# 파인튜닝 함수 정의\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=1):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # 데이터를 GPU로 이동\n",
        "            inputs = inputs.permute(0, 2, 1, 3, 4)  # 배치, 채널, 시간, 높이, 너비 순서로 변경\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        val_loss = 0.0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)  # 데이터를 GPU로 이동\n",
        "                inputs = inputs.permute(0, 2, 1, 3, 4)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
        "\n",
        "# 파인튜닝 실행\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uu4MV05bXKp4"
      },
      "outputs": [],
      "source": [
        "# 성능 평가 함수 정의\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.permute(0, 2, 1, 3, 4)  # 배치, 채널, 시간, 높이, 너비 순서로 변경\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# 성능 평가 실행\n",
        "accuracy = evaluate_model(model, test_loader)\n",
        "print(f\"Accuracy on benchmark dataset: {accuracy * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}